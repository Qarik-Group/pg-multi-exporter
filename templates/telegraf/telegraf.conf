(@ load("@ytt:data", "data") @)

[agent]
  metric_buffer_limit = 1800
  collection_jitter = "30s"
  flush_interval = "10s"
  flush_jitter = "5s"
(@ if hasattr(data.values.config, "telegraf"): @)
  debug = (@= "true" if data.values.config.telegraf.debug else "false" @)
(@ else: @)
  debug = false
(@ end @)


(@ if data.values.config.influxdb.endpoint.startswith("http"): @)
[[outputs.influxdb]]
  urls = ["(@= data.values.config.influxdb.endpoint @)"]
  name_prefix = "(@= data.values.config.influxdb.name_prefix @)"
(@ else: @)
[[outputs.socket_writer]]
  address = "(@= data.values.config.influxdb.endpoint @)"
  name_prefix = "(@= data.values.config.influxdb.name_prefix @)"
(@ end @)

# IAAS specific configs

(@ if hasattr(data.values.iaas_config, "gcp"): @)
(@ load("@ytt:json", "json") @)
[[inputs.stackdriver]]
  ## GCP Project
  project = "(@= json.decode(data.values.iaas_config.gcp.service_account)["project_id"] @)"

  ## Include timeseries that start with the given metric type.
  ## https://cloud.google.com/monitoring/api/metrics_gcp
  metric_type_prefix_include = [
    "cloudsql.googleapis.com/database/disk/read_ops_count",
    "cloudsql.googleapis.com/database/disk/write_ops_count",
    "cloudsql.googleapis.com/database/memory/utilization",
  ]

  interval = (@ if hasattr(data.values.iaas_config.gcp, "interval"): @) "(@= data.values.iaas_config.gcp.interval @)" (@ else: @) "1m" (@ end @)

[[processors.rename]]
  [[processors.rename.replace]]
    measurement = "cloudsql.googleapis.com/database/disk"
    dest = "database"
  [[processors.rename.replace]]
    measurement = "cloudsql.googleapis.com/database/memory"
    dest = "database"
  [[processors.rename.replace]]
    field = "utilization"
    dest = "memory_percentage"
(@ end @)

(@ if hasattr(data.values.iaas_config, "aws"): @)
[[inputs.cloudwatch]]
  region = "(@= data.values.iaas_config.aws.region @)"
  access_key = "(@= data.values.iaas_config.aws.access_key @)"
  secret_key = "(@= data.values.iaas_config.aws.secret_key @)"

  period = "5m"
  interval = (@ if hasattr(data.values.iaas_config.aws, "interval"): @) "(@= data.values.iaas_config.aws.interval @)" (@ else: @) "5m" (@ end @)
  delay = "5m"

  namespace = "AWS/RDS"

  ## metrics: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/MonitoringOverview.html
  [[inputs.cloudwatch.metrics]]
    names = ["CPUUtilization", "FreeableMemory", "ReadIOPS", "WriteIOPS", "FreeStorageSpace", "DatabaseConnections"]
    statistic_include = [ "average"]

    [[inputs.cloudwatch.metrics.dimensions]]
      name = "DBInstanceIdentifier"
      value = "*"

[[processors.rename]]
  [[processors.rename.replace]]
    measurement = "cloudwatch_aws_rds"
    dest = "database"
  [[processors.rename.replace]]
    field = "cpu_utilization_average"
    dest = "cpu_percentage"
  [[processors.rename.replace]]
    field = "freeable_memory_average"
    dest = "freeable_memory"
  [[processors.rename.replace]]
    field = "read_iops_average"
    dest = "read_ops_count"
  [[processors.rename.replace]]
    field = "write_iops_average"
    dest = "write_ops_count"
  [[processors.rename.replace]]
    field = "free_storage_space_average"
    dest = "free_disk_space"
(@ end @)

(@ if hasattr(data.values.iaas_config, "azure"): @)
## metrics: https://docs.microsoft.com/en-us/azure/postgresql/flexible-server/concepts-monitoring
##          https://docs.microsoft.com/en-us/azure/postgresql/concepts-monitoring
[[inputs.prometheus]]
  urls = ["http://localhost:9276/metrics"]
  interval = (@ if hasattr(data.values.iaas_config.azure, "interval"): @) "(@= data.values.iaas_config.azure.interval @)" (@ else: @) "1m" (@ end @)
  response_timeout = "10s"
  metric_version = 2
[[processors.rename]]
  [[processors.rename.replace]]
    measurement = "prometheus"
    dest = "database"
  [[processors.rename.replace]]
    field = "cpu_percent_percent_average"
    dest = "cpu_percentage"
  [[processors.rename.replace]]
    field = "memory_percent_percent_average"
    dest = "memory_percentage"
  [[processors.rename.replace]]
    field = "io_consumption_percent_percent_average"
    dest = "iops_percentage"
  [[processors.rename.replace]]
    field = "storage_percent_percent_average"
    dest = "storage_percentage"
  [[processors.rename.replace]]
    field = "active_connections_count_average"
    dest = "active_connections"
  [[processors.rename.replace]]
    field = "connections_failed_count_average"
    dest = "failed_connections"
(@ end @)

(@ if hasattr(data.values.iaas_config, "alicloud"): @)
## metrics: https://partners-intl.aliyun.com/help/doc-detail/28619.html?spm=a3c0i.10721930.0.0.26133d98BPW7pA
[[inputs.prometheus]]
  urls = ["http://localhost:9525/metrics"]
  interval = (@ if hasattr(data.values.iaas_config.alicloud, "interval"): @) "(@= data.values.iaas_config.alicloud.interval @)" (@ else: @) "5m" (@ end @)
  metric_version = 2
  response_timeout = "20s"
[[processors.rename]]
  [[processors.rename.replace]]
    measurement = "prometheus"
    dest = "database"

  [[processors.rename.replace]]
    field = "aliyun_acs_rds_dashboard_CpuUsage"
    dest = "cpu_percentage"
  [[processors.rename.replace]]
    field = "aliyun_acs_rds_dashboard_MemoryUsage"
    dest = "memory_percentage"
  [[processors.rename.replace]]
    field = "aliyun_acs_rds_dashboard_IOPSUsage"
    dest = "iops_percentage"
  [[processors.rename.replace]]
    field = "aliyun_acs_rds_dashboard_DiskUsage"
    dest = "storage_percentage"
  [[processors.rename.replace]]
    field = "aliyun_acs_rds_dashboard_ConnectionUsage"
    dest = "connections"
(@ end @)

(@ for d in data.values.config.databases: @)
[[inputs.postgresql]]
  interval = (@ if hasattr(d, "interval"): @) "(@= d.interval @)" (@ else: @) "2m" (@ end @)
  address = "host=(@= d.host @) port=(@= str(d.port) @) user=(@= d.username @) password=(@= d.password @) database=postgres sslmode=disable"

[[inputs.postgresql_extensible]]
  interval = (@ if hasattr(d, "interval"): @) "(@= d.interval @)" (@ else: @) "2m" (@ end @)
  address = "host=(@= d.host @) port=(@= str(d.port) @) user=(@= d.username @) password=(@= d.password @) database=postgres sslmode=disable"
  [[inputs.postgresql_extensible.query]]
    sqlquery='''
      SELECT t2.rolname as rolname, t3.datname as datname, queryid, calls,
	     total_time / 1000 as total_time_seconds,
	     min_time / 1000 as min_time_seconds,
	     max_time / 1000 as max_time_seconds,
	     mean_time / 1000 as mean_time_seconds,
	     stddev_time / 1000 as stddev_time_seconds,
	     rows,
	     shared_blks_hit, shared_blks_read, shared_blks_dirtied, shared_blks_written,
	     local_blks_hit, local_blks_read, local_blks_dirtied, local_blks_written,
	     temp_blks_read, temp_blks_written,
	     blk_read_time / 1000 as blk_read_time_seconds,
	     blk_write_time / 1000 as blk_write_time_seconds
      FROM pg_stat_statements t1
      JOIN pg_roles t2 ON (t1.userid=t2.oid)
      JOIN pg_database t3 ON (t1.dbid=t3.oid)
    '''
    version=11
    withdbname=false
    tagvalue="rolname,datname,queryid"
(@ end @)
